{"cells":[{"cell_type":"markdown","metadata":{"id":"Tce3stUlHN0L"},"source":["##### Copyright 2024 Google LLC."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"tuOe1ymfHZPu"},"outputs":[],"source":["# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"PzjeBM__IE1k"},"source":["# Gemini API: File API Quickstart\n","\n","<table align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"084u8u0DpBlo"},"source":["The Gemini API supports prompting with text, image, and audio data, also known as *multimodal* prompting. You can include text, image,\n","and audio in your prompts. For small images, you can point the Gemini model\n","directly to a local file when providing a prompt. For larger text files, images, videos, and audio, upload the files with the [File\n","API](https://ai.google.dev/api/rest/v1beta/files) before including them in\n","prompts.\n","\n","The File API lets you store up to 20GB of files per project, with each file not\n","exceeding 2GB in size. Files are stored for 48 hours and can be accessed with\n","your API key for generation within that time period. It is available at no cost in all regions where the [Gemini API is\n","available](https://ai.google.dev/available_regions).\n","\n","For information on valid file formats (MIME types) and supported models, see the documentation on\n","[supported file formats](https://ai.google.dev/tutorials/prompting_with_media#supported_file_formats)\n","and view the text examples at the end of this guide.\n","\n","This guide shows how to use the File API to upload a media file and include it in a `GenerateContent` call to the Gemini API. For more information, see the [code\n","samples](https://github.com/google-gemini/cookbook/tree/main/quickstarts/file-api).\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"_d_yY8XWGQ12","executionInfo":{"status":"ok","timestamp":1716724210243,"user_tz":-60,"elapsed":17827,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"outputs":[],"source":["!pip install -U -q google-generativeai"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"TeVyF3GtGQ13","executionInfo":{"status":"ok","timestamp":1716724217100,"user_tz":-60,"elapsed":1727,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"outputs":[],"source":["import google.generativeai as genai\n"]},{"cell_type":"markdown","metadata":{"id":"YdyC6Z6wqxz-"},"source":["## Authentication\n","\n","**Important:** The File API uses API keys for authentication and access. Uploaded files are associated with the API key's cloud project. Unlike other Gemini APIs that use API keys, your API key also grants access data you've uploaded to the File API, so take extra care in keeping your API key secure. For best practices on securing API keys, refer to Google's [documentation](https://support.google.com/googleapi/answer/6310037)."]},{"cell_type":"markdown","metadata":{"id":"l8g4hTRotheH"},"source":["### Setup your API key\n","\n","To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"iWd---jVKV5M","executionInfo":{"status":"ok","timestamp":1716724223466,"user_tz":-60,"elapsed":3775,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"outputs":[],"source":["from google.colab import userdata\n","\n","GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n","genai.configure(api_key=GOOGLE_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"c-z4zsCUlaru"},"source":["## Upload file\n","\n","The File API lets you upload a variety of multimodal MIME types, including images and audio formats. The File API handles inputs that can be used to generate content with [`model.generateContent`](https://ai.google.dev/api/rest/v1/models/generateContent) or [`model.streamGenerateContent`](https://ai.google.dev/api/rest/v1/models/streamGenerateContent).\n","\n","The File API accepts files under 2GB in size and can store up to 20GB of files per project. Files last for 2 days and cannot be downloaded from the API."]},{"cell_type":"markdown","metadata":{"id":"2wsJ0vHNNtdJ"},"source":["First, you will prepare a sample image to upload to the API.\n","\n","Note: You can also [upload your own files](https://github.com/google-gemini/cookbook/tree/main/examples/Upload_files_to_Colab.ipynb) to use."]},{"cell_type":"markdown","metadata":{"id":"u_aF5anOvKsO"},"source":["## Supported text types\n","\n","As well as supporting media uploads, the File API can be used to embed text files, such as Python code, or Markdown files, into your prompts.\n","\n","This example shows you how to load a markdown file into a prompt using the File API."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3Hz37jFBSr9l","executionInfo":{"status":"ok","timestamp":1716724301963,"user_tz":-60,"elapsed":591,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"outputs":[],"source":["# Download a markdown file and ask a question.\n","\n","!curl -so contrib.md https://raw.githubusercontent.com/google-gemini/cookbook/main/CONTRIBUTING.md\n","\n"]},{"cell_type":"code","source":["md_file = genai.upload_file(path=\"contrib.md\", display_name=\"Contributors guide\", mime_type=\"text/markdown\")\n","\n","model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")\n","response = model.generate_content(\n","    [\n","        \"What should I do before I start writing, when following these guidelines?\",\n","        md_file,\n","    ]\n",")\n","print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":523},"id":"M4PacIPyvfMz","executionInfo":{"status":"ok","timestamp":1716724327189,"user_tz":-60,"elapsed":14116,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}},"outputId":"b117bc05-5b56-4a9c-9ee4-de27afc41abe"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Here's a breakdown of what you need to do before writing, based on the provided guidelines:\n","\n","**Essentials:**\n","\n","1. **Sign the Google CLA:**\n","   -  This legal agreement is mandatory for all contributions.\n","   - Check if you or your employer have already signed it: [https://cla.developers.google.com/](https://cla.developers.google.com/)\n","   - If not, sign a new one through the link above.\n","\n","2. **Familiarize Yourself with Style Guides:**\n","   -  **Technical Writing:** Skim the highlights for common feedback points: [https://developers.google.com/style/highlights](https://developers.google.com/style/highlights)\n","   -  **Language-Specific:**  Identify the style guide for your chosen language (e.g., Python, JavaScript) here: [https://google.github.io/styleguide/](https://google.github.io/styleguide/)\n","   - **Python Notebooks:** If applicable, consider using `pyink` for style consistency in your `.ipynb` files.\n","\n","3. **Content Submission Protocol:**\n","   - **File an Issue:** *Before* writing any code, submit an issue on GitHub to discuss your idea: [https://github.com/google-gemini/cookbook/issues](https://github.com/google-gemini/cookbook/issues)\n","   - **Provide Context:**  Explain your guide's purpose, how it teaches Gemini API features, and if it's based on existing work.\n","\n","**Keep in Mind (Guide Acceptance Criteria):**\n","\n","* **Originality:** Your guide should offer something unique compared to existing resources.\n","* **Pedagogical Value:**  Clearly demonstrate how to use a Gemini API feature in a practical way.\n","* **High Quality:**  Ensure your code is understandable and your writing is clear and descriptive.\n","\n","**Attribution:**\n","\n","* If your guide is entirely original, you can include a byline at the top with your name and GitHub username. \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"pmmVaBz4Ss3W"},"source":["Some common text formats are automatically detected, such as `text/x-python`, `text/html` and `text/markdown`. If you are using a file that you know is text, but is not automatically detected by the API as such, you can specify the MIME type as `text/plain` explicitly."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"8m4qpfTqzE9o","executionInfo":{"status":"ok","timestamp":1716724463085,"user_tz":-60,"elapsed":701,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"outputs":[],"source":["# Download some C++ code and force the MIME as text when uploading.\n","\n","!curl -so gemma.cpp https://raw.githubusercontent.com/google/gemma.cpp/main/examples/hello_world/run.cc\n","\n"]},{"cell_type":"code","source":["cpp_file = genai.upload_file(\n","    path=\"gemma.cpp\", display_name=\"gemma.cpp\", mime_type=\"text/plain\"\n",")\n","\n"],"metadata":{"id":"o1g8fWOKwE8l","executionInfo":{"status":"ok","timestamp":1716724478030,"user_tz":-60,"elapsed":2678,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")\n","response = model.generate_content([\"What does this program do?\", cpp_file])\n","print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":835},"id":"d0FSrbPLwGN1","executionInfo":{"status":"ok","timestamp":1716724501783,"user_tz":-60,"elapsed":18166,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}},"outputId":"19ca73e7-3c64-491b-ade4-3f96338e6a57"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["This C++ program demonstrates the use of the **Gemma** language model for text generation. Let's break down what the code does step-by-step:\n","\n","**1. Initialization and Setup**\n","\n","   * **Includes:** The code includes necessary header files for input/output, the Gemma library (`gemma.h`), thread pool management, and command-line argument parsing.\n","   * **Licensing:** The initial lines specify the licensing (Apache 2.0) for the code.\n","   * **Thread Pool:** A thread pool (`hwy::ThreadPool`) is created to leverage multi-threading for potentially faster inference.\n","   * **Model and Cache Loading:**\n","      * `gcpp::LoaderArgs loader(argc, argv);`  parses command-line arguments likely related to model loading (e.g., paths to weight files).\n","      *  `gcpp::Gemma model(loader.tokenizer, loader.weights, loader.ModelType(), pool);`  instantiates the Gemma model, using the specified tokenizer, model weights, model type, and the thread pool.\n","      * `auto kv_cache = CreateKVCache(loader.ModelType());` creates a Key-Value (KV) cache. This cache likely stores intermediate activations during the model's generation process to improve efficiency.\n","   * **Random Number Generator:** A random number generator (`std::mt19937`) is initialized for sampling during text generation.\n","\n","**2. Text Preparation and Tokenization**\n","\n","   * **Tokenization Function (`tokenize`)**:\n","      * Takes a prompt string as input.\n","      * Adds special tokens to mark the beginning and end of user and model turns (`<start_of_turn>`, `<end_of_turn>`).\n","      * Uses the Gemma tokenizer (`model.Tokenizer()`) to convert the text into a sequence of numerical tokens (`std::vector<int> tokens`).\n","   * **Instruction Tokenization:**\n","     *  `std::vector<int> tokens = tokenize(\"Write a greeting to the world.\", model.Tokenizer());` tokenizes the initial instruction \"Write a greeting to the world.\"\n","\n","**3. Text Generation**\n","\n","   * **`stream_token` Callback:**\n","      * This function is called every time Gemma generates a new token. \n","      * It receives the generated token (`int token`) and its probability (`float`, unused here).\n","      * It keeps track of the generation progress (`pos`).\n","      * If all input tokens have been processed (`pos >= ntokens`), it prints the decoded text representation of the generated token.\n","   * **`GenerateGemma` Function:**\n","      *  `GenerateGemma(model, {/*generation parameters*/}, tokens, /*KV cache position = */ 0, kv_cache, pool, stream_token, gen);`  initiates the text generation process using the loaded Gemma model and the tokenized instruction. \n","      * **Generation Parameters:**\n","         * `max_tokens`: Limits the total number of tokens (input + generated).\n","         * `max_generated_tokens`: Limits the number of tokens generated.\n","         * `temperature`: Controls the randomness of generation (higher temperature, more random).\n","         * `verbosity`: Controls the amount of logging/debugging information.\n","      * It uses the provided KV cache, thread pool, the `stream_token` callback, and the random number generator.\n","\n","**4. Output**\n","\n","   * The generated text, token by token, is printed to the console (`std::cout`). \n","\n","**In Essence:**\n","\n","The program takes an instruction (\"Write a greeting to the world.\"), feeds it to the Gemma language model, and generates text based on that instruction. The generated text is then printed to the console. The code demonstrates a typical workflow for using a pre-trained language model for text generation tasks. \n","\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}